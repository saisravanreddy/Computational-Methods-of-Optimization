{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Nocedal Chapter 3 Page 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_min_slope = 0.5\n",
    "beta_ratio_decrease_t = 0.5\n",
    "epsilon = 10**(-7)\n",
    "X_initial = [10, 100, 100, 10]\n",
    "#print(type(X_initial))\n",
    "\n",
    "#Loading functions and gradients\n",
    "func = dill.loads(pickle.load(open(\"f6.pkl\",\"rb\")))\n",
    "func_grad = dill.loads(pickle.load(open(\"grad_f6.pkl\",\"rb\")))\n",
    "\n",
    "func_map = {}\n",
    "func_calls = 0\n",
    "func_grad_map = {}\n",
    "func_grad_calls = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_line_search_based_gradient_descent(alpha_min_slope, beta_ratio_decrease_t, X, epsilon, func, func_grad):\n",
    "    iterations = 0\n",
    "\n",
    "    while(1):\n",
    "        print(\"Iteration number: {}\".format(iterations+1))\n",
    "        u = -1.*func_grad(X)\n",
    "        t = 1\n",
    "        while (func(X+t*u) > (func(X) + alpha_min_slope*t*np.matmul(np.matrix.transpose(func_grad(X)),u))):\n",
    "            t = beta_ratio_decrease_t * t\n",
    "            \n",
    "        X = X + t*u\n",
    "        iterations += 1\n",
    "        if np.linalg.norm(t*u) < epsilon:\n",
    "            break\n",
    "    \n",
    "    return X,iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number: 1\n",
      "Function gradient value not present for X:[10, 100, 100, 10]\n",
      "Function value not present for X:[  -8. -292. -482.  -38.]\n",
      "Function value not present for X:[10, 100, 100, 10]\n",
      "Function gradient value already present for X:[10, 100, 100, 10]\n",
      "Function value not present for X:[   1.  -96. -191.  -14.]\n",
      "Function value already present for X: [10, 100, 100, 10]\n",
      "Function gradient value already present for X:[10, 100, 100, 10]\n",
      "Function value not present for X:[  5.5   2.  -45.5  -2. ]\n",
      "Function value already present for X: [10, 100, 100, 10]\n",
      "Function gradient value already present for X:[10, 100, 100, 10]\n",
      "Function value not present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Function value already present for X: [10, 100, 100, 10]\n",
      "Function gradient value already present for X:[10, 100, 100, 10]\n",
      "Iteration number: 2\n",
      "Function gradient value not present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Function value not present for X:[  -5.75 -145.   -118.25    4.  ]\n",
      "Function value already present for X: [ 7.75 51.   27.25  4.  ]\n",
      "Function gradient value already present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Function value not present for X:[  1.  -47.  -45.5   4. ]\n",
      "Function value already present for X: [ 7.75 51.   27.25  4.  ]\n",
      "Function gradient value already present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Function value not present for X:[ 4.375  2.    -9.125  4.   ]\n",
      "Function value already present for X: [ 7.75 51.   27.25  4.  ]\n",
      "Function gradient value already present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Function value not present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Function value already present for X: [ 7.75 51.   27.25  4.  ]\n",
      "Function gradient value already present for X:[ 7.75 51.   27.25  4.  ]\n",
      "Iteration number: 3\n",
      "Function gradient value not present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Function value not present for X:[ -4.0625 -71.5    -27.3125   4.    ]\n",
      "Function value already present for X: [ 6.0625 26.5     9.0625  4.    ]\n",
      "Function gradient value already present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Function value not present for X:[  1.    -22.5    -9.125   4.   ]\n",
      "Function value already present for X: [ 6.0625 26.5     9.0625  4.    ]\n",
      "Function gradient value already present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Function value not present for X:[ 3.53125  2.      -0.03125  4.     ]\n",
      "Function value already present for X: [ 6.0625 26.5     9.0625  4.    ]\n",
      "Function gradient value already present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Function value not present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Function value already present for X: [ 6.0625 26.5     9.0625  4.    ]\n",
      "Function gradient value already present for X:[ 6.0625 26.5     9.0625  4.    ]\n",
      "Iteration number: 4\n",
      "Function gradient value not present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Function value not present for X:[ -2.796875 -34.75      -4.578125   4.      ]\n",
      "Function value already present for X: [ 4.796875 14.25      4.515625  4.      ]\n",
      "Function gradient value already present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Function value not present for X:[  1.      -10.25     -0.03125   4.     ]\n",
      "Function value already present for X: [ 4.796875 14.25      4.515625  4.      ]\n",
      "Function gradient value already present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Function value not present for X:[2.8984375 2.        2.2421875 4.       ]\n",
      "Function value already present for X: [ 4.796875 14.25      4.515625  4.      ]\n",
      "Function gradient value already present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Function value not present for X:[3.84765625 8.125      3.37890625 4.        ]\n",
      "Function value already present for X: [ 4.796875 14.25      4.515625  4.      ]\n",
      "Function gradient value already present for X:[ 4.796875 14.25      4.515625  4.      ]\n",
      "Iteration number: 5\n",
      "Function gradient value not present for X:[3.84765625 8.125      3.37890625 4.        ]\n",
      "Function value not present for X:[ -1.84765625 -16.375        1.10546875   4.        ]\n",
      "Function value already present for X: [3.84765625 8.125      3.37890625 4.        ]\n",
      "Function gradient value already present for X:[3.84765625 8.125      3.37890625 4.        ]\n",
      "Function value not present for X:[ 1.        -4.125      2.2421875  4.       ]\n",
      "Function value already present for X: [3.84765625 8.125      3.37890625 4.        ]\n",
      "Function gradient value already present for X:[3.84765625 8.125      3.37890625 4.        ]\n",
      "Function value not present for X:[2.42382812 2.         2.81054688 4.        ]\n",
      "Function value already present for X: [3.84765625 8.125      3.37890625 4.        ]\n",
      "Function gradient value already present for X:[3.84765625 8.125      3.37890625 4.        ]\n",
      "Iteration number: 6\n",
      "Function gradient value not present for X:[2.42382812 2.         2.81054688 4.        ]\n",
      "Function value not present for X:[-0.42382812  2.          3.94726562  4.        ]\n",
      "Function value already present for X: [2.42382812 2.         2.81054688 4.        ]\n",
      "Function gradient value already present for X:[2.42382812 2.         2.81054688 4.        ]\n",
      "Function value not present for X:[1.         2.         3.37890625 4.        ]\n",
      "Function value already present for X: [2.42382812 2.         2.81054688 4.        ]\n",
      "Function gradient value already present for X:[2.42382812 2.         2.81054688 4.        ]\n",
      "Function value not present for X:[1.71191406 2.         3.09472656 4.        ]\n",
      "Function value already present for X: [2.42382812 2.         2.81054688 4.        ]\n",
      "Function gradient value already present for X:[2.42382812 2.         2.81054688 4.        ]\n",
      "Iteration number: 7\n",
      "Function gradient value not present for X:[1.71191406 2.         3.09472656 4.        ]\n",
      "Function value not present for X:[0.28808594 2.         2.52636719 4.        ]\n",
      "Function value already present for X: [1.71191406 2.         3.09472656 4.        ]\n",
      "Function gradient value already present for X:[1.71191406 2.         3.09472656 4.        ]\n",
      "Function value not present for X:[1.         2.         2.81054688 4.        ]\n",
      "Function value already present for X: [1.71191406 2.         3.09472656 4.        ]\n",
      "Function gradient value already present for X:[1.71191406 2.         3.09472656 4.        ]\n",
      "Function value not present for X:[1.35595703 2.         2.95263672 4.        ]\n",
      "Function value already present for X: [1.71191406 2.         3.09472656 4.        ]\n",
      "Function gradient value already present for X:[1.71191406 2.         3.09472656 4.        ]\n",
      "Iteration number: 8\n",
      "Function gradient value not present for X:[1.35595703 2.         2.95263672 4.        ]\n",
      "Function value not present for X:[0.64404297 2.         3.23681641 4.        ]\n",
      "Function value already present for X: [1.35595703 2.         2.95263672 4.        ]\n",
      "Function gradient value already present for X:[1.35595703 2.         2.95263672 4.        ]\n",
      "Function value not present for X:[1.         2.         3.09472656 4.        ]\n",
      "Function value already present for X: [1.35595703 2.         2.95263672 4.        ]\n",
      "Function gradient value already present for X:[1.35595703 2.         2.95263672 4.        ]\n",
      "Function value not present for X:[1.17797852 2.         3.02368164 4.        ]\n",
      "Function value already present for X: [1.35595703 2.         2.95263672 4.        ]\n",
      "Function gradient value already present for X:[1.35595703 2.         2.95263672 4.        ]\n",
      "Iteration number: 9\n",
      "Function gradient value not present for X:[1.17797852 2.         3.02368164 4.        ]\n",
      "Function value not present for X:[0.82202148 2.         2.8815918  4.        ]\n",
      "Function value already present for X: [1.17797852 2.         3.02368164 4.        ]\n",
      "Function gradient value already present for X:[1.17797852 2.         3.02368164 4.        ]\n",
      "Function value not present for X:[1.         2.         2.95263672 4.        ]\n",
      "Function value already present for X: [1.17797852 2.         3.02368164 4.        ]\n",
      "Function gradient value already present for X:[1.17797852 2.         3.02368164 4.        ]\n",
      "Function value not present for X:[1.08898926 2.         2.98815918 4.        ]\n",
      "Function value already present for X: [1.17797852 2.         3.02368164 4.        ]\n",
      "Function gradient value already present for X:[1.17797852 2.         3.02368164 4.        ]\n",
      "Iteration number: 10\n",
      "Function gradient value not present for X:[1.08898926 2.         2.98815918 4.        ]\n",
      "Function value not present for X:[0.91101074 2.         3.0592041  4.        ]\n",
      "Function value already present for X: [1.08898926 2.         2.98815918 4.        ]\n",
      "Function gradient value already present for X:[1.08898926 2.         2.98815918 4.        ]\n",
      "Function value not present for X:[1.         2.         3.02368164 4.        ]\n",
      "Function value already present for X: [1.08898926 2.         2.98815918 4.        ]\n",
      "Function gradient value already present for X:[1.08898926 2.         2.98815918 4.        ]\n",
      "Function value not present for X:[1.04449463 2.         3.00592041 4.        ]\n",
      "Function value already present for X: [1.08898926 2.         2.98815918 4.        ]\n",
      "Function gradient value already present for X:[1.08898926 2.         2.98815918 4.        ]\n",
      "Iteration number: 11\n",
      "Function gradient value not present for X:[1.04449463 2.         3.00592041 4.        ]\n",
      "Function value not present for X:[0.95550537 2.         2.97039795 4.        ]\n",
      "Function value already present for X: [1.04449463 2.         3.00592041 4.        ]\n",
      "Function gradient value already present for X:[1.04449463 2.         3.00592041 4.        ]\n",
      "Function value not present for X:[1.         2.         2.98815918 4.        ]\n",
      "Function value already present for X: [1.04449463 2.         3.00592041 4.        ]\n",
      "Function gradient value already present for X:[1.04449463 2.         3.00592041 4.        ]\n",
      "Function value not present for X:[1.02224731 2.         2.99703979 4.        ]\n",
      "Function value already present for X: [1.04449463 2.         3.00592041 4.        ]\n",
      "Function gradient value already present for X:[1.04449463 2.         3.00592041 4.        ]\n",
      "Iteration number: 12\n",
      "Function gradient value not present for X:[1.02224731 2.         2.99703979 4.        ]\n",
      "Function value not present for X:[0.97775269 2.         3.01480103 4.        ]\n",
      "Function value already present for X: [1.02224731 2.         2.99703979 4.        ]\n",
      "Function gradient value already present for X:[1.02224731 2.         2.99703979 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00592041 4.        ]\n",
      "Function value already present for X: [1.02224731 2.         2.99703979 4.        ]\n",
      "Function gradient value already present for X:[1.02224731 2.         2.99703979 4.        ]\n",
      "Function value not present for X:[1.01112366 2.         3.0014801  4.        ]\n",
      "Function value already present for X: [1.02224731 2.         2.99703979 4.        ]\n",
      "Function gradient value already present for X:[1.02224731 2.         2.99703979 4.        ]\n",
      "Iteration number: 13\n",
      "Function gradient value not present for X:[1.01112366 2.         3.0014801  4.        ]\n",
      "Function value not present for X:[0.98887634 2.         2.99259949 4.        ]\n",
      "Function value already present for X: [1.01112366 2.         3.0014801  4.        ]\n",
      "Function gradient value already present for X:[1.01112366 2.         3.0014801  4.        ]\n",
      "Function value not present for X:[1.         2.         2.99703979 4.        ]\n",
      "Function value already present for X: [1.01112366 2.         3.0014801  4.        ]\n",
      "Function gradient value already present for X:[1.01112366 2.         3.0014801  4.        ]\n",
      "Function value not present for X:[1.00556183 2.         2.99925995 4.        ]\n",
      "Function value already present for X: [1.01112366 2.         3.0014801  4.        ]\n",
      "Function gradient value already present for X:[1.01112366 2.         3.0014801  4.        ]\n",
      "Iteration number: 14\n",
      "Function gradient value not present for X:[1.00556183 2.         2.99925995 4.        ]\n",
      "Function value not present for X:[0.99443817 2.         3.00370026 4.        ]\n",
      "Function value already present for X: [1.00556183 2.         2.99925995 4.        ]\n",
      "Function gradient value already present for X:[1.00556183 2.         2.99925995 4.        ]\n",
      "Function value not present for X:[1.        2.        3.0014801 4.       ]\n",
      "Function value already present for X: [1.00556183 2.         2.99925995 4.        ]\n",
      "Function gradient value already present for X:[1.00556183 2.         2.99925995 4.        ]\n",
      "Function value not present for X:[1.00278091 2.         3.00037003 4.        ]\n",
      "Function value already present for X: [1.00556183 2.         2.99925995 4.        ]\n",
      "Function gradient value already present for X:[1.00556183 2.         2.99925995 4.        ]\n",
      "Iteration number: 15\n",
      "Function gradient value not present for X:[1.00278091 2.         3.00037003 4.        ]\n",
      "Function value not present for X:[0.99721909 2.         2.99814987 4.        ]\n",
      "Function value already present for X: [1.00278091 2.         3.00037003 4.        ]\n",
      "Function gradient value already present for X:[1.00278091 2.         3.00037003 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99925995 4.        ]\n",
      "Function value already present for X: [1.00278091 2.         3.00037003 4.        ]\n",
      "Function gradient value already present for X:[1.00278091 2.         3.00037003 4.        ]\n",
      "Function value not present for X:[1.00139046 2.         2.99981499 4.        ]\n",
      "Function value already present for X: [1.00278091 2.         3.00037003 4.        ]\n",
      "Function gradient value already present for X:[1.00278091 2.         3.00037003 4.        ]\n",
      "Iteration number: 16\n",
      "Function gradient value not present for X:[1.00139046 2.         2.99981499 4.        ]\n",
      "Function value not present for X:[0.99860954 2.         3.00092506 4.        ]\n",
      "Function value already present for X: [1.00139046 2.         2.99981499 4.        ]\n",
      "Function gradient value already present for X:[1.00139046 2.         2.99981499 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00037003 4.        ]\n",
      "Function value already present for X: [1.00139046 2.         2.99981499 4.        ]\n",
      "Function gradient value already present for X:[1.00139046 2.         2.99981499 4.        ]\n",
      "Function value not present for X:[1.00069523 2.         3.00009251 4.        ]\n",
      "Function value already present for X: [1.00139046 2.         2.99981499 4.        ]\n",
      "Function gradient value already present for X:[1.00139046 2.         2.99981499 4.        ]\n",
      "Iteration number: 17\n",
      "Function gradient value not present for X:[1.00069523 2.         3.00009251 4.        ]\n",
      "Function value not present for X:[0.99930477 2.         2.99953747 4.        ]\n",
      "Function value already present for X: [1.00069523 2.         3.00009251 4.        ]\n",
      "Function gradient value already present for X:[1.00069523 2.         3.00009251 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99981499 4.        ]\n",
      "Function value already present for X: [1.00069523 2.         3.00009251 4.        ]\n",
      "Function gradient value already present for X:[1.00069523 2.         3.00009251 4.        ]\n",
      "Function value not present for X:[1.00034761 2.         2.99995375 4.        ]\n",
      "Function value already present for X: [1.00069523 2.         3.00009251 4.        ]\n",
      "Function gradient value already present for X:[1.00069523 2.         3.00009251 4.        ]\n",
      "Iteration number: 18\n",
      "Function gradient value not present for X:[1.00034761 2.         2.99995375 4.        ]\n",
      "Function value not present for X:[0.99965239 2.         3.00023127 4.        ]\n",
      "Function value already present for X: [1.00034761 2.         2.99995375 4.        ]\n",
      "Function gradient value already present for X:[1.00034761 2.         2.99995375 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00009251 4.        ]\n",
      "Function value already present for X: [1.00034761 2.         2.99995375 4.        ]\n",
      "Function gradient value already present for X:[1.00034761 2.         2.99995375 4.        ]\n",
      "Function value not present for X:[1.00017381 2.         3.00002313 4.        ]\n",
      "Function value already present for X: [1.00034761 2.         2.99995375 4.        ]\n",
      "Function gradient value already present for X:[1.00034761 2.         2.99995375 4.        ]\n",
      "Iteration number: 19\n",
      "Function gradient value not present for X:[1.00017381 2.         3.00002313 4.        ]\n",
      "Function value not present for X:[0.99982619 2.         2.99988437 4.        ]\n",
      "Function value already present for X: [1.00017381 2.         3.00002313 4.        ]\n",
      "Function gradient value already present for X:[1.00017381 2.         3.00002313 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99995375 4.        ]\n",
      "Function value already present for X: [1.00017381 2.         3.00002313 4.        ]\n",
      "Function gradient value already present for X:[1.00017381 2.         3.00002313 4.        ]\n",
      "Function value not present for X:[1.0000869  2.         2.99998844 4.        ]\n",
      "Function value already present for X: [1.00017381 2.         3.00002313 4.        ]\n",
      "Function gradient value already present for X:[1.00017381 2.         3.00002313 4.        ]\n",
      "Iteration number: 20\n",
      "Function gradient value not present for X:[1.0000869  2.         2.99998844 4.        ]\n",
      "Function value not present for X:[0.9999131  2.         3.00005782 4.        ]\n",
      "Function value already present for X: [1.0000869  2.         2.99998844 4.        ]\n",
      "Function gradient value already present for X:[1.0000869  2.         2.99998844 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00002313 4.        ]\n",
      "Function value already present for X: [1.0000869  2.         2.99998844 4.        ]\n",
      "Function gradient value already present for X:[1.0000869  2.         2.99998844 4.        ]\n",
      "Function value not present for X:[1.00004345 2.         3.00000578 4.        ]\n",
      "Function value already present for X: [1.0000869  2.         2.99998844 4.        ]\n",
      "Function gradient value already present for X:[1.0000869  2.         2.99998844 4.        ]\n",
      "Iteration number: 21\n",
      "Function gradient value not present for X:[1.00004345 2.         3.00000578 4.        ]\n",
      "Function value not present for X:[0.99995655 2.         2.99997109 4.        ]\n",
      "Function value already present for X: [1.00004345 2.         3.00000578 4.        ]\n",
      "Function gradient value already present for X:[1.00004345 2.         3.00000578 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99998844 4.        ]\n",
      "Function value already present for X: [1.00004345 2.         3.00000578 4.        ]\n",
      "Function gradient value already present for X:[1.00004345 2.         3.00000578 4.        ]\n",
      "Function value not present for X:[1.00002173 2.         2.99999711 4.        ]\n",
      "Function value already present for X: [1.00004345 2.         3.00000578 4.        ]\n",
      "Function gradient value already present for X:[1.00004345 2.         3.00000578 4.        ]\n",
      "Iteration number: 22\n",
      "Function gradient value not present for X:[1.00002173 2.         2.99999711 4.        ]\n",
      "Function value not present for X:[0.99997827 2.         3.00001445 4.        ]\n",
      "Function value already present for X: [1.00002173 2.         2.99999711 4.        ]\n",
      "Function gradient value already present for X:[1.00002173 2.         2.99999711 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00000578 4.        ]\n",
      "Function value already present for X: [1.00002173 2.         2.99999711 4.        ]\n",
      "Function gradient value already present for X:[1.00002173 2.         2.99999711 4.        ]\n",
      "Function value not present for X:[1.00001086 2.         3.00000145 4.        ]\n",
      "Function value already present for X: [1.00002173 2.         2.99999711 4.        ]\n",
      "Function gradient value already present for X:[1.00002173 2.         2.99999711 4.        ]\n",
      "Iteration number: 23\n",
      "Function gradient value not present for X:[1.00001086 2.         3.00000145 4.        ]\n",
      "Function value not present for X:[0.99998914 2.         2.99999277 4.        ]\n",
      "Function value already present for X: [1.00001086 2.         3.00000145 4.        ]\n",
      "Function gradient value already present for X:[1.00001086 2.         3.00000145 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99999711 4.        ]\n",
      "Function value already present for X: [1.00001086 2.         3.00000145 4.        ]\n",
      "Function gradient value already present for X:[1.00001086 2.         3.00000145 4.        ]\n",
      "Function value not present for X:[1.00000543 2.         2.99999928 4.        ]\n",
      "Function value already present for X: [1.00001086 2.         3.00000145 4.        ]\n",
      "Function gradient value already present for X:[1.00001086 2.         3.00000145 4.        ]\n",
      "Iteration number: 24\n",
      "Function gradient value not present for X:[1.00000543 2.         2.99999928 4.        ]\n",
      "Function value not present for X:[0.99999457 2.         3.00000361 4.        ]\n",
      "Function value already present for X: [1.00000543 2.         2.99999928 4.        ]\n",
      "Function gradient value already present for X:[1.00000543 2.         2.99999928 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00000145 4.        ]\n",
      "Function value already present for X: [1.00000543 2.         2.99999928 4.        ]\n",
      "Function gradient value already present for X:[1.00000543 2.         2.99999928 4.        ]\n",
      "Function value not present for X:[1.00000272 2.         3.00000036 4.        ]\n",
      "Function value already present for X: [1.00000543 2.         2.99999928 4.        ]\n",
      "Function gradient value already present for X:[1.00000543 2.         2.99999928 4.        ]\n",
      "Iteration number: 25\n",
      "Function gradient value not present for X:[1.00000272 2.         3.00000036 4.        ]\n",
      "Function value not present for X:[0.99999728 2.         2.99999819 4.        ]\n",
      "Function value already present for X: [1.00000272 2.         3.00000036 4.        ]\n",
      "Function gradient value already present for X:[1.00000272 2.         3.00000036 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99999928 4.        ]\n",
      "Function value already present for X: [1.00000272 2.         3.00000036 4.        ]\n",
      "Function gradient value already present for X:[1.00000272 2.         3.00000036 4.        ]\n",
      "Function value not present for X:[1.00000136 2.         2.99999982 4.        ]\n",
      "Function value already present for X: [1.00000272 2.         3.00000036 4.        ]\n",
      "Function gradient value already present for X:[1.00000272 2.         3.00000036 4.        ]\n",
      "Iteration number: 26\n",
      "Function gradient value not present for X:[1.00000136 2.         2.99999982 4.        ]\n",
      "Function value not present for X:[0.99999864 2.         3.0000009  4.        ]\n",
      "Function value already present for X: [1.00000136 2.         2.99999982 4.        ]\n",
      "Function gradient value already present for X:[1.00000136 2.         2.99999982 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00000036 4.        ]\n",
      "Function value already present for X: [1.00000136 2.         2.99999982 4.        ]\n",
      "Function gradient value already present for X:[1.00000136 2.         2.99999982 4.        ]\n",
      "Function value not present for X:[1.00000068 2.         3.00000009 4.        ]\n",
      "Function value already present for X: [1.00000136 2.         2.99999982 4.        ]\n",
      "Function gradient value already present for X:[1.00000136 2.         2.99999982 4.        ]\n",
      "Iteration number: 27\n",
      "Function gradient value not present for X:[1.00000068 2.         3.00000009 4.        ]\n",
      "Function value not present for X:[0.99999932 2.         2.99999955 4.        ]\n",
      "Function value already present for X: [1.00000068 2.         3.00000009 4.        ]\n",
      "Function gradient value already present for X:[1.00000068 2.         3.00000009 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99999982 4.        ]\n",
      "Function value already present for X: [1.00000068 2.         3.00000009 4.        ]\n",
      "Function gradient value already present for X:[1.00000068 2.         3.00000009 4.        ]\n",
      "Function value not present for X:[1.00000034 2.         2.99999995 4.        ]\n",
      "Function value already present for X: [1.00000068 2.         3.00000009 4.        ]\n",
      "Function gradient value already present for X:[1.00000068 2.         3.00000009 4.        ]\n",
      "Iteration number: 28\n",
      "Function gradient value not present for X:[1.00000034 2.         2.99999995 4.        ]\n",
      "Function value not present for X:[0.99999966 2.         3.00000023 4.        ]\n",
      "Function value already present for X: [1.00000034 2.         2.99999995 4.        ]\n",
      "Function gradient value already present for X:[1.00000034 2.         2.99999995 4.        ]\n",
      "Function value not present for X:[1.         2.         3.00000009 4.        ]\n",
      "Function value already present for X: [1.00000034 2.         2.99999995 4.        ]\n",
      "Function gradient value already present for X:[1.00000034 2.         2.99999995 4.        ]\n",
      "Function value not present for X:[1.00000017 2.         3.00000002 4.        ]\n",
      "Function value already present for X: [1.00000034 2.         2.99999995 4.        ]\n",
      "Function gradient value already present for X:[1.00000034 2.         2.99999995 4.        ]\n",
      "Iteration number: 29\n",
      "Function gradient value not present for X:[1.00000017 2.         3.00000002 4.        ]\n",
      "Function value not present for X:[0.99999983 2.         2.99999989 4.        ]\n",
      "Function value already present for X: [1.00000017 2.         3.00000002 4.        ]\n",
      "Function gradient value already present for X:[1.00000017 2.         3.00000002 4.        ]\n",
      "Function value not present for X:[1.         2.         2.99999995 4.        ]\n",
      "Function value already present for X: [1.00000017 2.         3.00000002 4.        ]\n",
      "Function gradient value already present for X:[1.00000017 2.         3.00000002 4.        ]\n",
      "Function value not present for X:[1.00000008 2.         2.99999999 4.        ]\n",
      "Function value already present for X: [1.00000017 2.         3.00000002 4.        ]\n",
      "Function gradient value already present for X:[1.00000017 2.         3.00000002 4.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def func_with_call_counter(X):\n",
    "    global func_calls\n",
    "    if tuple(X) in func_map.keys():\n",
    "        print(\"Function value already present for X: {}\".format(X))\n",
    "        return func_map[tuple(X)]\n",
    "    else:\n",
    "        print(\"Function value not present for X:{}\".format(X))\n",
    "        func_calls += 1\n",
    "        func_map[tuple(X)] = func(X)\n",
    "        return func_map[tuple(X)]\n",
    "    \n",
    "def func_grad_with_call_counter(X):\n",
    "    global func_grad_calls\n",
    "    if tuple(X) in func_grad_map.keys():\n",
    "        print(\"Function gradient value already present for X:{}\".format(X))\n",
    "        return func_grad_map[tuple(X)]\n",
    "    else:\n",
    "        print(\"Function gradient value not present for X:{}\".format(X))\n",
    "        func_grad_calls += 1\n",
    "        func_grad_map[tuple(X)] = np.array(func_grad(X))\n",
    "        return func_grad_map[tuple(X)]\n",
    "\n",
    "#Backtracking line search\n",
    "X_final, iterations = backtracking_line_search_based_gradient_descent(alpha_min_slope, \n",
    "                                                                      beta_ratio_decrease_t, \n",
    "                                                                      X_initial, \n",
    "                                                                      epsilon, \n",
    "                                                                      func_with_call_counter, \n",
    "                                                                      func_grad_with_call_counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hat: [1.00000008 2.         2.99999999 4.        ] \t iterations:29 \n",
      " function calls:92 \t gradient calls:29\n"
     ]
    }
   ],
   "source": [
    "print(\"X_hat: {} \\t iterations:{} \\n function calls:{} \\t gradient calls:{}\".format(X_final, iterations, func_calls, func_grad_calls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37_env",
   "language": "python",
   "name": "py_37_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
